{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272ccddc",
   "metadata": {},
   "source": [
    "# Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "61d27c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/3Sakshi/AI/20049006 Sakshi Gupta\\20049006 Sakshi Gupta.ipynb\n",
      "/3Sakshi/AI/20049006 Sakshi Gupta\\.ipynb_checkpoints\\20049006 Sakshi Gupta-checkpoint.ipynb\n",
      "/3Sakshi/AI/20049006 Sakshi Gupta\\dataset\\test.txt\n",
      "/3Sakshi/AI/20049006 Sakshi Gupta\\dataset\\train.txt\n",
      "/3Sakshi/AI/20049006 Sakshi Gupta\\dataset\\val.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import math\n",
    "#import mlxtend\n",
    "#import sklearn.cluster as cluster\n",
    "#import sklearn.neighbors\n",
    "import sklearn.metrics as metrics\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/3Sakshi/AI/20049006 Sakshi Gupta'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a015c3d",
   "metadata": {},
   "source": [
    "# Load and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3597af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: (20000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('../20049006 Sakshi Gupta/dataset/train.txt',names=['sentence','emotion'],header=None, sep=';')\n",
    "test_data = pd.read_csv('../20049006 Sakshi Gupta/dataset/test.txt',names=['sentence','emotion'],header=None, sep=';')\n",
    "val_data= pd.read_csv('../20049006 Sakshi Gupta/dataset/val.txt',names=['sentence','emotion'],header=None, sep=';')\n",
    "df = pd.concat([train_data,test_data, val_data])\n",
    "print('Total data:',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84b729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1dde266b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 2)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(keep=\"first\") # Drop duplicated data and reindex the data\n",
    "df_reidx = df.reset_index(drop=True)\n",
    "df_reidx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "edd9ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the emotions to binary labels. love and joy emotions are \"not-stressed ==1\", and sadness, anger, fear, and surprise are \"stressed == 0\".\n",
    "df_reidx['label']=df_reidx['emotion'].replace({'joy': \"not-stressed\" , 'love': \"not-stressed\", \n",
    "                                   'sadness': \"stressed\", 'anger': \"stressed\", 'fear': \"stressed\",'surprise': \"stressed\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0ec51bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stressed        11598\n",
       "not-stressed     8401\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if pos and neg sentiments\n",
    "df_reidx.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "12245250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19999.000000\n",
       "mean        96.671784\n",
       "std         55.778779\n",
       "min          7.000000\n",
       "25%         53.000000\n",
       "50%         86.000000\n",
       "75%        129.000000\n",
       "max        300.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reidx['length'] = df_reidx['sentence'].apply(len) # number of characters\n",
    "df_reidx['length'].describe() # info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5fe248f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>stressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "      <td>joy</td>\n",
       "      <td>not-stressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "      <td>joy</td>\n",
       "      <td>not-stressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "      <td>joy</td>\n",
       "      <td>not-stressed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>not-stressed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  emotion  \\\n",
       "19994  im having ssa examination tomorrow in the morn...  sadness   \n",
       "19995  i constantly worry about their fight against n...      joy   \n",
       "19996  i feel its important to share this info for th...      joy   \n",
       "19997  i truly feel that if you are passionate enough...      joy   \n",
       "19998  i feel like i just wanna buy any cute make up ...      joy   \n",
       "\n",
       "              label  \n",
       "19994      stressed  \n",
       "19995  not-stressed  \n",
       "19996  not-stressed  \n",
       "19997  not-stressed  \n",
       "19998  not-stressed  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reidx.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4690bc",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "To clean the sentences,we do text preprocessing.\n",
    "1. Decontracted\n",
    "2. Data cleaning\n",
    "3. Spell check\n",
    "4. Lemmatization\n",
    "5. Nomalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6f64bb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 19999/19999 [00:03<00:00, 5093.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>stressed</td>\n",
       "      <td>i did not feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>stressed</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>stressed</td>\n",
       "      <td>i am grabbing a minute to post i feel greedy w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>not-stressed</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>stressed</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  emotion         label  \\\n",
       "0                            i didnt feel humiliated  sadness      stressed   \n",
       "1  i can go from feeling so hopeless to so damned...  sadness      stressed   \n",
       "2   im grabbing a minute to post i feel greedy wrong    anger      stressed   \n",
       "3  i am ever feeling nostalgic about the fireplac...     love  not-stressed   \n",
       "4                               i am feeling grouchy    anger      stressed   \n",
       "\n",
       "                                    cleaned_sentence  \n",
       "0                          i did not feel humiliated  \n",
       "1  i can go from feeling so hopeless to so damned...  \n",
       "2  i am grabbing a minute to post i feel greedy w...  \n",
       "3  i am ever feeling nostalgic about the fireplac...  \n",
       "4                               i am feeling grouchy  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "#from nltk.stem import PorterStemmer\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def decontracted(phrase):\n",
    "    \"\"\"\n",
    "    We first define a function to expand the contracted phrase into normal words\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"wont\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"wouldnt\", \"would not\", phrase)\n",
    "    phrase = re.sub(r\"shouldnt\", \"should not\", phrase)\n",
    "    phrase = re.sub(r\"couldnt\", \"could not\", phrase)\n",
    "    phrase = re.sub(r\"cudnt\", \"could not\", phrase)\n",
    "    phrase = re.sub(r\"cant\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"dont\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"doesnt\", \"does not\", phrase)\n",
    "    phrase = re.sub(r\"didnt\", \"did not\", phrase)\n",
    "    phrase = re.sub(r\"wasnt\", \"was not\", phrase)\n",
    "    phrase = re.sub(r\"werent\", \"were not\", phrase)\n",
    "    phrase = re.sub(r\"havent\", \"have not\", phrase)\n",
    "    phrase = re.sub(r\"hadnt\", \"had not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\ t\", \" not\", phrase)\n",
    "    #phrase = re.sub(r\"\\re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\ s \", \" is \", phrase) # prime \n",
    "    phrase = re.sub(r\"\\ d \", \" would \", phrase)\n",
    "    phrase = re.sub(r\"\\ ll \", \" will \", phrase)\n",
    "    phrase = re.sub(r\"\\dunno\", \"do not \", phrase)\n",
    "    phrase = re.sub(r\"ive \", \"i have \", phrase)\n",
    "    phrase = re.sub(r\"im \", \"i am \", phrase)\n",
    "    phrase = re.sub(r\"i m \", \"i am \", phrase)\n",
    "    phrase = re.sub(r\" w \", \" with \", phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "    \n",
    "def clean_text(df):\n",
    "    \"\"\"\n",
    "    Clean the review texts\n",
    "    \"\"\"\n",
    "    cleaned_review = []\n",
    "\n",
    "    for review_text in tqdm(df['sentence']):\n",
    "        \n",
    "        # expand the contracted words\n",
    "        review_text = decontracted(review_text)\n",
    "        #remove html tags\n",
    "        review_text = BeautifulSoup(review_text, 'lxml').get_text().strip() # re.sub(r'<.*?>', '', text)\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #remove url \n",
    "        review_text = re.sub(r'https?://\\S+|www\\.\\S+', '', review_text)\n",
    "        \n",
    "        #Removing punctutation, string.punctuation in python consists of !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n",
    "        review_text = review_text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # ''.join([char for char in movie_text_data if char not in string.punctuation])\n",
    "        \n",
    "        # remove emails\n",
    "        review_text = re.sub(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", '', review_text)\n",
    "    \n",
    "        cleaned_review.append(review_text)\n",
    "\n",
    "    return cleaned_review  \n",
    "\n",
    "df_reidx['cleaned_sentence'] = clean_text(df_reidx)\n",
    "df_reidx.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4db23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c341af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d9a7154",
   "metadata": {},
   "source": [
    "# Additional Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "76191ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 19999/19999 [00:02<00:00, 8196.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>emotion</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>stressed</td>\n",
       "      <td>[feel, humiliated]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>stressed</td>\n",
       "      <td>[go, feeling, hopeless, damned, hopeful, aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>stressed</td>\n",
       "      <td>[grabbing, minute, post, feel, greedy, wrong]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>not-stressed</td>\n",
       "      <td>[ever, feeling, nostalgic, fireplace, know, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>stressed</td>\n",
       "      <td>[feeling, grouchy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  emotion         label  \\\n",
       "0                            i didnt feel humiliated  sadness      stressed   \n",
       "1  i can go from feeling so hopeless to so damned...  sadness      stressed   \n",
       "2   im grabbing a minute to post i feel greedy wrong    anger      stressed   \n",
       "3  i am ever feeling nostalgic about the fireplac...     love  not-stressed   \n",
       "4                               i am feeling grouchy    anger      stressed   \n",
       "\n",
       "                                    cleaned_sentence  \n",
       "0                                 [feel, humiliated]  \n",
       "1  [go, feeling, hopeless, damned, hopeful, aroun...  \n",
       "2      [grabbing, minute, post, feel, greedy, wrong]  \n",
       "3  [ever, feeling, nostalgic, fireplace, know, st...  \n",
       "4                                 [feeling, grouchy]  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "def remove_stopwords(phrase):\n",
    "    remove_sw = []\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    for review_text in tqdm(phrase):\n",
    "        tokens = word_tokenize(review_text)\n",
    "        tokens = [word for word in tokens if not word in stop_words]\n",
    "        remove_sw.append(tokens)\n",
    "    return remove_sw\n",
    "\n",
    "df_reidx['cleaned_sentence'] = remove_stopwords(df_reidx['cleaned_sentence'])\n",
    "df_reidx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75544714",
   "metadata": {},
   "source": [
    "# Not Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4bd3b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming for extract the actual meaning of the words\n",
    "#from nltk.stem import PorterStemmer\n",
    "\n",
    "#def stemming(phrase):\n",
    "#    stemmer = PorterStemmer()\n",
    "#    stem_output=[]\n",
    "#    stemmed=[]\n",
    "#    for review_text in tqdm(phrase):\n",
    "#        stemmed = [stemmer.stem(word) for word in review_text]\n",
    "#        stem_output.append(stemmed)\n",
    "#    return stem_output\n",
    "\n",
    "#df_reidx['cleaned_sentence'] = stemming(df_reidx['cleaned_sentence'])\n",
    "#df_reidx['cleaned_sentence'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f62976ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 19999/19999 [00:00<00:00, 1251221.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                      feel humiliated\n",
       "1    go feeling hopeless damned hopeful around some...\n",
       "2               grabbing minute post feel greedy wrong\n",
       "3    ever feeling nostalgic fireplace know still no...\n",
       "4                                      feeling grouchy\n",
       "Name: cleaned_sentence, dtype: object"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_sentence(phrase):\n",
    "    sentence=[]\n",
    "    for words in tqdm(phrase):\n",
    "        sentence.append((\" \").join(words))\n",
    "    return sentence\n",
    "df_reidx['cleaned_sentence']=to_sentence(df_reidx['cleaned_sentence'])\n",
    "df_reidx['cleaned_sentence'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5b27b",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43c2eb",
   "metadata": {},
   "source": [
    "CounterVectorize: tokenization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bc947564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape :  (19999, 5673)\n",
      "y.shape :  (19999,)\n"
     ]
    }
   ],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=0.5, min_df=3, ngram_range=(1,1),tokenizer = token.tokenize)\n",
    "x = vectorizer.fit_transform(df_reidx.cleaned_sentence)\n",
    "y = df_reidx.label.values\n",
    "\n",
    "print(\"X.shape : \",x.shape)\n",
    "print(\"y.shape : \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6058a6d",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "29bbfac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:13999\n",
      "Number of testing examples:6000\n",
      "\n",
      "Training data: X_train : (13999, 5673), y_train : (13999,)\n",
      "Testing data: X_test : (6000, 5673), y_test : (6000,)\n"
     ]
    }
   ],
   "source": [
    "# do shuffle to make neg and pos data of data set split equaly in the test and training set\n",
    "# do random_sate for making it settle when we run this code repeatedly\n",
    "train_idx, test_idx = train_test_split(np.arange(df_reidx.shape[0]), test_size=0.3,shuffle=True, random_state=42)\n",
    "\n",
    "x_train = x[train_idx]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "x_test = x[test_idx]\n",
    "y_test = y[test_idx]\n",
    "print(\"Number of training examples:{}\".format(len(train_idx)))\n",
    "print(\"Number of testing examples:{}\\n\".format(len(test_idx)))\n",
    "print(\"Training data: X_train : {}, y_train : {}\".format(x_train.shape, y_train.shape))\n",
    "print(\"Testing data: X_test : {}, y_test : {}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2128c21",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4871f60d",
   "metadata": {},
   "source": [
    "MultinominaliNB\n",
    "\n",
    "It consider a feature vector where a given term represents the number of times it appears or very ofen, such as frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f0eb5131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "not-stressed       0.94      0.93      0.93      2491\n",
      "    stressed       0.95      0.96      0.95      3509\n",
      "\n",
      "    accuracy                           0.95      6000\n",
      "   macro avg       0.94      0.94      0.94      6000\n",
      "weighted avg       0.95      0.95      0.95      6000\n",
      "\n",
      "\n",
      "Accuracy for multinominal Naive Bayes model: 0.9455\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "# make prediction on testing data\n",
    "y_pred_test_mnb = mnb.predict(x_test)\n",
    "y_predprob_mnb = mnb.predict_proba(x_test)\n",
    "matrix = confusion_matrix(y_test,y_pred_test_mnb)\n",
    "print(classification_report(y_test, y_pred_test_mnb))\n",
    "print(\"\\nAccuracy for multinominal Naive Bayes model:\",metrics.accuracy_score(y_test, y_pred_test_mnb))\n",
    "print(\"\\n\")\n",
    "\n",
    "y_predict = mnb.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01a7b4",
   "metadata": {},
   "source": [
    "# Explain the model predection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3d0bd768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stressed' 'not-stressed' 'stressed' 'not-stressed' 'stressed']\n"
     ]
    }
   ],
   "source": [
    "text=['i am not feeling well', 'i want to make this project better', 'i feel aaaaaaah', 'i want to live', 'i want to die']\n",
    "test_result = mnb.predict(vectorizer.transform(text))\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b64f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
